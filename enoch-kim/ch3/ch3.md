# 일반적인 데이터 파이프라인 패턴

다양한 사용사례로 확장 가능한 성공적인 공통 패턴을 다룬다.

## ETL과 ELT

가장 대표적인 파이프라인 패턴으로 파이프라인과 동의어로 취급되기도 한다.

- 데이터 웨어하우징에 뿌리를 두고 있음

- 데이터 웨어하우스에 데이터를 공급하고 분석가나 보고 도구가 이를 유용하게 쓸 수 있게 하는 방식

- 다음 세가지 단계로 구성
    - extract(추출): 로드 및 변환을 준비하기 위해 다양한 소스에서 데이터를 수집
    - load(로드): 원본데이터 혹은 완전히 변환된 데이터를 최종 대상으로 가져오는 경우, 결국 웨어하우스나 레이크 등의 대상에 데이터를 로드하는 것
    - transform(변환): 파이프라인이 제공하는 모든 사용 사례에 유용하게 쓸 수 있게 각 소스 시스템의 원본 데이터를 결합하고 형식을 지정하는 단계(6장 참조..)

- 왜 ELT 가 등장했는가?
    - as-is
        - 클라우드 기반 웨어하우스가 아니었기 때문에 로드 후 변환할 충분한 스토리지와 컴퓨팅 자원이 없었다
        - 행 기반 웨어하우스(ex. Mysql) 사용
            - 적은 양의 데이터를 자주 읽고 쓰는 OLTP(Online Transaction Processing)에는 적합하지만 대규모 데이터를 분석하는데 좋지 못했다
            - 행 기반으로 저장 시 각 블록 크기를 정의된 레코드의 크기와 동일하게 가져가야함 -> 적은 데이터가 있더라도 빈 공간(hole 상태)으로 두게됨 -> 저장공간 비효율 초래
            - 블럭에 서로 다른 타입의 정보들이 저장되기 때문에 압축 최적화를 할 수 없음(ex String과 BigInt가 있는 행에 String 압축 방식을 사용하면 BigInt는 압축 효율이 떨어짐)

    - to-be
        - 클라우드 기반 웨어하우스에서 자원을 결합하여 사용하므로 자원 부족 문제가 해결됨
        - 열 기반 웨어하우스(ex. hadoop, mongo) 사용
            - 많은 양의 데이터를 드물게 읽고 쓰는 OLAP(Online Analytical Processing)에 적합하다
                - 열 단위로 디스크에 저장하기 때문에 특정 열만을 읽어 분석하는 과정에서 디스크 I/O가 줄어든다
            - 무엇보다 블럭에 동일한 타입의 정보들이 저장되기 때문에 압축을 최적화할 수 있다 (ex String 만 있는 열에 ~ 압축방식을 사용)

- EtLT
    - ELT 방식을 사용할때 필요없는 데이터를 저장하여 스토리지 낭비가 발생 -> 간단한 변환들로 쓸데없는 데이터를 제거해주는 t 과정이 포함
    - 이 외에도 비즈니스 로직과 분리된 작업을 해주거나 법적, 보안상 이슈를 미리 처리해주는 작업이 t에 속한다
    - t 작업으로 다음과 같은 것들이 있다
        - 테이블에서 레코드 중복 제거
        - URL 파라미터를 개별 구성용소로 구문 분석
        - 민감한 데이터 마스킹 또는 난독화

- ELT의 등장으로 인한 롤 영향
    - 데이터 분석가
        - 분석가와 엔지니어 사이의 역할이 명확히 분리 된다
        - 기존에는 변환하고 분석하는 과정이 선후되어야 하기 때문에 분석가와 엔지니어가 긴밀히 협력했어야했음
        - 이젠 미리 로드 시킨 데이터를 분석가가 SQL을 통해 분석하면 되기 때문에 엔지니어가 로드 후 관여하지 않아도 됨
            - 근데 우린 왜.. 둘..다..?
        - 또한 보다 raw 한 데이터를 로드해두기 때문에 분석가는 더 유연하고 다양하게 분석이 가능하다

    - 데이터과학자
        - 분석가보다 더 raw 하고 광범위한 데이터를 다루기 쉬운데, ELT가 이를 충족해준다
        - 이 책에 따르면 과학자 > 분석가 > 엔지니어 인 것인가.. ㅠ
    
    - 머신러닝 데이터과학자
        - 머신러닝을 사용한 데이터 제품을 개발하는데 도움된다
        - 머신러닝의 경우 파이프라인이 분석가가 사용하는 방식에 몇가지 머신러닝 모델을 빌드하고 업데이트 하는 과정이 추가된다
            - 데이터 수집 -> 전처리 -> 모델 학습 -> 배포 단계로 간략화 할 수 있다
            - 이외에도 사용자 피드백 수집 및 반영 등의 과정이 포함된다면 더 좋은 제품이 탄생할 것이다
